{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import semisup\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_integer('emb_size', 256, 'Dimension of embedding space')\n",
    "\n",
    "flags.DEFINE_integer('sup_per_class', 2,\n",
    "                     'Number of labeled samples used per class.')\n",
    "\n",
    "flags.DEFINE_integer('sup_seed', -1,  #-1 -> choose randomly   -2 -> use sup_per_class as seed\n",
    "                     'Integer random seed used for labeled set selection.')\n",
    "\n",
    "flags.DEFINE_integer('sup_per_batch', -1,   #-1 -> take all available\n",
    "                     'Number of labeled samples per class per batch.')\n",
    "\n",
    "flags.DEFINE_integer('unsup_batch_size', 10,\n",
    "                     'Number of unlabeled samples per batch.')\n",
    "\n",
    "flags.DEFINE_integer('eval_interval', 500,\n",
    "                     'Number of steps between evaluations.')\n",
    "\n",
    "flags.DEFINE_string('architecture', 'alexnet_model', 'Which network architecture '\n",
    "                                                           'from architectures.py to use.' )\n",
    "\n",
    "flags.DEFINE_float('learning_rate', 1e-3, 'Initial learning rate.')\n",
    "\n",
    "flags.DEFINE_float('decay_factor', 0.33, 'Learning rate decay factor.')\n",
    "\n",
    "flags.DEFINE_float('decay_steps', 5000,\n",
    "                   'Learning rate decay interval in steps.')\n",
    "\n",
    "flags.DEFINE_float('visit_weight', 1.0, 'Weight for visit loss.')\n",
    "\n",
    "flags.DEFINE_float('walker_weight', 1.0, 'Weight for walker loss.')\n",
    "flags.DEFINE_float('logit_weight', 1.0, 'Weight for logits')\n",
    "flags.DEFINE_float('dropout_keep_prob', 1.0, 'Dropout factor.')\n",
    "flags.DEFINE_float('l1_weight', 0.0002, 'Weight for l1 embeddding regularization')\n",
    "\n",
    "flags.DEFINE_integer('warmup_steps', 1000, 'Number of training steps.')\n",
    "flags.DEFINE_integer('max_steps', 20000, 'Number of training steps.')\n",
    "\n",
    "flags.DEFINE_string('logdir', '/tmp/semisup_mnist', 'Training log path.')\n",
    "\n",
    "flags.DEFINE_bool('semisup', True, 'Add unsupervised samples')\n",
    "\n",
    "flags.DEFINE_bool('augmentation', True,\n",
    "                  'Apply data augmentation during training.')\n",
    "\n",
    "flags.DEFINE_float('batch_norm_decay', 0.99,\n",
    "                   'Batch norm decay factor '\n",
    "                   '(only used for STL-10 at the moment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
